{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:46:32.107834Z",
     "start_time": "2025-02-26T07:46:30.445728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from braindecode.datasets import MOABBDataset\n",
    "\n",
    "subject_id = 3\n",
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[subject_id])"
   ],
   "id": "da33564dc5ebcc33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:49:27.245721Z",
     "start_time": "2025-02-26T07:49:08.913916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize,\n",
    "    preprocess,\n",
    "    Preprocessor,\n",
    ")\n",
    "\n",
    "low_cut_hz = 4.0  # low cut frequency for filtering\n",
    "high_cut_hz = 38.0  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(\"pick_types\", eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    Preprocessor(\n",
    "        lambda data, factor: np.multiply(data, factor),  # Convert from V to uV\n",
    "        factor=1e6,\n",
    "    ),\n",
    "    Preprocessor(\"filter\", l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    Preprocessor(\n",
    "        exponential_moving_standardize,  # Exponential moving standardization\n",
    "        factor_new=factor_new,\n",
    "        init_block_size=init_block_size,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Preprocess the data\n",
    "preprocess(dataset, preprocessors, n_jobs=-1)"
   ],
   "id": "b0f48149fff9d516",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xialugui\\PycharmProjects\\eeg_mi_dl\\.venv\\lib\\site-packages\\braindecode\\preprocessing\\preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.moabb.MOABBDataset at 0x2ca48cdba30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:50:20.311911Z",
     "start_time": "2025-02-26T07:50:20.254898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from braindecode.preprocessing import create_windows_from_events\n",
    "\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info[\"sfreq\"]\n",
    "assert all([ds.raw.info[\"sfreq\"] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the window start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to\n",
    "# define how windows should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    preload=True,\n",
    ")"
   ],
   "id": "16235d62cc9ef862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:53:15.651905Z",
     "start_time": "2025-02-26T07:53:15.630903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitted = windows_dataset.split(\"session\")\n",
    "train_set = splitted[\"0train\"]  # Session train\n",
    "test_set = splitted[\"1test\"]  # Session evaluation"
   ],
   "id": "1deeda9bba7ad3cd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:53:44.182001Z",
     "start_time": "2025-02-26T07:53:44.132994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet,EEGNetv4,EEGNetv1\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = \"cuda\" if cuda else \"cpu\"\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "classes = list(range(n_classes))\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_channels = windows_dataset[0][0].shape[0]\n",
    "n_times = windows_dataset[0][0].shape[1]\n",
    "\n",
    "model = EEGNetv4(\n",
    "    n_chans=n_channels,\n",
    "    n_outputs=n_classes,\n",
    "    n_times=n_times,\n",
    "    final_conv_length=\"auto\",\n",
    ")\n",
    "\n",
    "# Display torchinfo table describing the model\n",
    "print(model)\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ],
   "id": "f561e354219cae5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 22, 1125]             [1, 4]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 22, 1125]             [1, 22, 1125, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 22, 1125, 1]          [1, 1, 1125, 22]          --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1125, 22]          [1, 40, 1101, 1]          36,240                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 40, 1101, 1]          [1, 40, 1101, 1]          80                        --\n",
      "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 1101, 1]          [1, 40, 1101, 1]          --                        --\n",
      "├─AvgPool2d (pool): 1-6                  [1, 40, 1101, 1]          [1, 40, 69, 1]            --                        [75, 1]\n",
      "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 69, 1]            [1, 40, 69, 1]            --                        --\n",
      "├─Dropout (drop): 1-8                    [1, 40, 69, 1]            [1, 40, 69, 1]            --                        --\n",
      "├─Sequential (final_layer): 1-9          [1, 40, 69, 1]            [1, 4]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 69, 1]            [1, 4, 1, 1]              11,044                    [69, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 4, 1, 1]              [1, 4, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 47,364\n",
      "Trainable params: 47,364\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.01\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.50\n",
      "============================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xialugui\\PycharmProjects\\eeg_mi_dl\\.venv\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:55:37.427527Z",
     "start_time": "2025-02-26T07:55:35.314323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    from skorch.callbacks import LRScheduler\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "n_epochs = 2\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=None,\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    "    max_epochs=n_epochs,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(train_set, y=None)\n",
    "\n",
    "# evaluated the model after training\n",
    "y_test = test_set.get_metadata().target\n",
    "test_acc = clf.score(test_set, y=y_test)\n",
    "print(f\"Test acc: {(test_acc * 100):.2f}%\")"
   ],
   "id": "dbad649f79ee8b4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2500\u001B[0m        \u001B[32m1.6001\u001B[0m  0.0006  0.6542\n",
      "      2            0.2500        \u001B[32m1.2351\u001B[0m  0.0000  0.6051\n",
      "Test acc: 25.00%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:57:02.706903Z",
     "start_time": "2025-02-26T07:57:02.654891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skorch.helper import predefined_split, SliceDataset\n",
    "\n",
    "X_train = SliceDataset(train_set, idx=0)\n",
    "y_train = np.array([y for y in SliceDataset(train_set, idx=1)])\n",
    "train_indices, val_indices = train_test_split(\n",
    "    X_train.indices_, test_size=0.2, shuffle=False\n",
    ")\n",
    "train_subset = Subset(train_set, train_indices)\n",
    "val_subset = Subset(train_set, val_indices)"
   ],
   "id": "f0de7cde6c2fcbf0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:57:26.319694Z",
     "start_time": "2025-02-26T07:57:24.141171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(val_subset),\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    "    max_epochs=n_epochs,\n",
    ")\n",
    "clf.fit(train_subset, y=None)\n",
    "\n",
    "# evaluate the model after training and validation\n",
    "y_test = test_set.get_metadata().target\n",
    "test_acc = clf.score(test_set, y=y_test)\n",
    "print(f\"Test acc: {(test_acc * 100):.2f}%\")"
   ],
   "id": "60942b112dbcd9bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  ------------  -----------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3217\u001B[0m        \u001B[32m1.3036\u001B[0m       \u001B[35m0.3103\u001B[0m            \u001B[31m0.3103\u001B[0m        \u001B[94m4.6925\u001B[0m  0.0006  0.8970\n",
      "      2            \u001B[36m0.3435\u001B[0m        \u001B[32m1.1317\u001B[0m       0.2931            0.2931        \u001B[94m4.1178\u001B[0m  0.0000  0.5364\n",
      "Test acc: 27.43%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T07:58:58.655874Z",
     "start_time": "2025-02-26T07:58:51.664933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "n_epochs = 2\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=None,\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    "    max_epochs=n_epochs,\n",
    ")\n",
    "\n",
    "train_val_split = KFold(n_splits=5, shuffle=False)\n",
    "# By setting n_jobs=-1, cross-validation is performed\n",
    "# with all the processors, in this case the output of the training\n",
    "# process is not printed sequentially\n",
    "cv_results = cross_val_score(\n",
    "    clf, X_train, y_train, scoring=\"accuracy\", cv=train_val_split, n_jobs=1\n",
    ")\n",
    "print(\n",
    "    f\"Validation accuracy: {np.mean(cv_results * 100):.2f}\"\n",
    "    f\"+-{np.std(cv_results * 100):.2f}%\"\n",
    ")"
   ],
   "id": "10b75b4de3341993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2783\u001B[0m        \u001B[32m1.1248\u001B[0m  0.0006  0.5286\n",
      "      2            \u001B[36m0.2870\u001B[0m        \u001B[32m1.0725\u001B[0m  0.0000  0.4796\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2609\u001B[0m        \u001B[32m1.1297\u001B[0m  0.0006  0.4674\n",
      "      2            0.2609        \u001B[32m1.0006\u001B[0m  0.0000  0.4408\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3783\u001B[0m        \u001B[32m1.1716\u001B[0m  0.0006  0.4221\n",
      "      2            0.3739        \u001B[32m1.0291\u001B[0m  0.0000  0.4431\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2554\u001B[0m        \u001B[32m1.1478\u001B[0m  0.0006  0.4287\n",
      "      2            \u001B[36m0.2597\u001B[0m        \u001B[32m0.9408\u001B[0m  0.0000  0.4161\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3939\u001B[0m        \u001B[32m1.0697\u001B[0m  0.0006  0.4655\n",
      "      2            0.3939        \u001B[32m0.9915\u001B[0m  0.0000  0.4187\n",
      "Validation accuracy: 29.15+-6.43%\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T08:01:56.917051Z",
     "start_time": "2025-02-26T08:01:51.916577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_val_split = [\n",
    "    tuple(train_test_split(X_train.indices_, test_size=0.2, shuffle=False))\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    \"optimizer__lr\": [0.00625, 0.000625],\n",
    "}\n",
    "\n",
    "# By setting n_jobs=-1, grid search is performed\n",
    "# with all the processors, in this case the output of the training\n",
    "# process is not printed sequentially\n",
    "search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=train_val_split,\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    refit=True,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "search_results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "best_run = search_results[search_results[\"rank_test_score\"] == 1].squeeze()\n",
    "\n",
    "best_parameters = best_run[\"params\"]"
   ],
   "id": "4784b4c30a0881f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 2 candidates, totalling 2 fits\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3043\u001B[0m        \u001B[32m1.4458\u001B[0m  0.0063  0.5211\n",
      "      2            \u001B[36m0.3609\u001B[0m        \u001B[32m1.1274\u001B[0m  0.0000  0.4531\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2739\u001B[0m        \u001B[32m1.0392\u001B[0m  0.0006  0.4471\n",
      "      2            0.2739        \u001B[32m0.9765\u001B[0m  0.0000  0.4541\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2639\u001B[0m        \u001B[32m1.5059\u001B[0m  0.0063  0.5863\n",
      "      2            \u001B[36m0.3299\u001B[0m        \u001B[32m1.2135\u001B[0m  0.0000  0.5967\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T08:03:52.740674Z",
     "start_time": "2025-02-26T08:03:34.921953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_val_split = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "param_grid = {\n",
    "    \"optimizer__lr\": [0.00625, 0.000625],\n",
    "}\n",
    "\n",
    "# By setting n_jobs=-1, grid search is performed\n",
    "# with all the processors, in this case the output of the training\n",
    "# process is not printed sequentially\n",
    "search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=train_val_split,\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    refit=True,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "search_results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "best_run = search_results[search_results[\"rank_test_score\"] == 1].squeeze()\n",
    "\n",
    "best_parameters = best_run[\"params\"]"
   ],
   "id": "d34663225f823d1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3217\u001B[0m        \u001B[32m1.6345\u001B[0m  0.0063  0.5441\n",
      "      2            \u001B[36m0.3565\u001B[0m        \u001B[32m1.2107\u001B[0m  0.0000  0.5022\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2913\u001B[0m        \u001B[32m1.6300\u001B[0m  0.0063  0.4467\n",
      "      2            \u001B[36m0.3522\u001B[0m        \u001B[32m1.3015\u001B[0m  0.0000  0.4371\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3957\u001B[0m        \u001B[32m1.6227\u001B[0m  0.0063  0.4181\n",
      "      2            \u001B[36m0.4261\u001B[0m        \u001B[32m1.2540\u001B[0m  0.0000  0.4389\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3593\u001B[0m        \u001B[32m1.4726\u001B[0m  0.0063  0.4267\n",
      "      2            \u001B[36m0.4416\u001B[0m        \u001B[32m1.0335\u001B[0m  0.0000  0.4321\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3810\u001B[0m        \u001B[32m1.5056\u001B[0m  0.0063  0.4311\n",
      "      2            \u001B[36m0.4416\u001B[0m        \u001B[32m1.2078\u001B[0m  0.0000  0.4338\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.3435\u001B[0m        \u001B[32m1.1884\u001B[0m  0.0006  0.4480\n",
      "      2            \u001B[36m0.3565\u001B[0m        \u001B[32m1.0686\u001B[0m  0.0000  0.4351\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2609\u001B[0m        \u001B[32m1.1603\u001B[0m  0.0006  0.4141\n",
      "      2            \u001B[36m0.2652\u001B[0m        \u001B[32m1.0137\u001B[0m  0.0000  0.4787\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2957\u001B[0m        \u001B[32m1.1871\u001B[0m  0.0006  0.4489\n",
      "      2            0.2957        \u001B[32m1.0107\u001B[0m  0.0000  0.4836\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2727\u001B[0m        \u001B[32m1.1931\u001B[0m  0.0006  0.4117\n",
      "      2            \u001B[36m0.2771\u001B[0m        \u001B[32m1.0750\u001B[0m  0.0000  0.4461\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2511\u001B[0m        \u001B[32m1.1127\u001B[0m  0.0006  0.4601\n",
      "      2            0.2511        \u001B[32m0.9826\u001B[0m  0.0000  0.4211\n",
      "  epoch    train_accuracy    train_loss      lr     dur\n",
      "-------  ----------------  ------------  ------  ------\n",
      "      1            \u001B[36m0.2778\u001B[0m        \u001B[32m1.5792\u001B[0m  0.0063  0.5846\n",
      "      2            \u001B[36m0.3264\u001B[0m        \u001B[32m1.2402\u001B[0m  0.0000  0.5871\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
